{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from imp import reload\n",
    "import itertools\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, MaxPooling1D, Convolution1D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n",
      "Number of words: \n",
      "4998\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes: \")\n",
    "print(np.unique(y))\n",
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to set a proper max sequence length, we need to go througth the property of the data and see the length distribution of each sentence in the dataset. A box and whisker plot is shown below for reviewing the length distribution in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269077d5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking the box and whisker plot, the max length of a sample in words is 500, and the mean and median are below 250. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 399s 16ms/step - loss: 0.4428 - acc: 0.7894 - val_loss: 0.3862 - val_acc: 0.8305\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 389s 16ms/step - loss: 0.3036 - acc: 0.8774 - val_loss: 0.3584 - val_acc: 0.8505\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 398s 16ms/step - loss: 0.2512 - acc: 0.9014 - val_loss: 0.3125 - val_acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2690dbbbc88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, 32, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores =  model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87     12500\n",
      "          1       0.89      0.85      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict= model.predict(X_test)\n",
    "y_predict = (y_predict >= 0.5)\n",
    "print (classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model with convolutional layer with an LSTM layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = 6000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 64)          384000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 495,297\n",
      "Trainable params: 495,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(top_words,64, dropout=0.2))\n",
    "model.add(Convolution1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 335s 13ms/step - loss: 0.4878 - acc: 0.7442\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 340s 14ms/step - loss: 0.3243 - acc: 0.8658\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 348s 14ms/step - loss: 0.2477 - acc: 0.9030\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 353s 14ms/step - loss: 0.2103 - acc: 0.9192\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 352s 14ms/step - loss: 0.1853 - acc: 0.9298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2693aebdfd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.96%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy is higher in this case and dimensionality is also less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (25000, 500)\n",
      "Test data size: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=500)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=500)\n",
    "\n",
    "print('Train data size:', x_train.shape)\n",
    "print('Test data size:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 498, 250)          24250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 247,251\n",
      "Trainable params: 247,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000,32,input_length=500))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250,3,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(250))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 282s 11ms/step - loss: 0.4560 - acc: 0.7592 - val_loss: 0.2879 - val_acc: 0.8785\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 280s 11ms/step - loss: 0.2560 - acc: 0.8966 - val_loss: 0.2591 - val_acc: 0.8916\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 330s 13ms/step - loss: 0.1880 - acc: 0.9272 - val_loss: 0.2923 - val_acc: 0.8801\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 513s 21ms/step - loss: 0.1438 - acc: 0.9465 - val_loss: 0.2743 - val_acc: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26941e91b38>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,batch_size=64,epochs=4,validation_data=(x_test, y_test),verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.14%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.88      0.89     12500\n",
      "          1       0.88      0.90      0.89     12500\n",
      "\n",
      "avg / total       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict= model.predict(x_test)\n",
    "y_predict = (y_predict >= 0.5)\n",
    "print (classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Accuracy : 89.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
